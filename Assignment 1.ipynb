{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the webpage\n",
    "url = 'https://www.notebooksbilliger.de/markenwelten/apple'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract item titles and prices\n",
    "items = soup.find_all('div', class_='product-card.js-process-cards', limit=10)\n",
    "data = []\n",
    "\n",
    "for item in items:\n",
    "    title = item.find('div', class_='product-card__product-heading-title').text.strip()\n",
    "    \n",
    "    data.append({'title': title})\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('apple_products1.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Fetch and parse the webpage\n",
    "url = 'https://www.notebooksbilliger.de/markenwelten/apple'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Assuming item titles and prices are contained within specific class names\n",
    "# These class names are placeholders and must be replaced with actual ones\n",
    "item_titles = soup.find_all('div', class_='product-card__product-heading-title', limit=10)\n",
    "\n",
    "# Data sanitization and storing in DataFrame\n",
    "data = {\n",
    "    'Title': [title.text.strip() for title in item_titles],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Save the DataFrame to a CSV file\n",
    "df.to_csv('items.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple MacBook Air 13,6\" M3 MRXV3D/A Mitternacht\n",
      "Apple MacBook Pro MRX33D/A Space Schwarz\n",
      "Apple MacBook Air (M1, 2020) MGN63D/A SpaceGrau\n",
      "Apple MacBook Air 13\" (M2, 2022) MLXW3D/A Space Grau\n",
      "Apple MacBook Air (M2, 2022) MLY33D/A Mitternacht\n",
      "Apple MacBook Air 13,6\" 2022,Apple M2 Chip 8-Core,8-Core GPU\n",
      "Apple MacBook Air 13,6\" M3 CZ1BD-0001000 Mitternacht\n",
      "Apple MacBook Pro (M2, 2022) CZ16T-0120000 Silver\n",
      "Apple MacBook Air 15\" (M2, 2023) CTO Mitternacht\n",
      "Apple MacBook Air M2 MLXY3D/A Silber\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = 'https://www.notebooksbilliger.de/notebooks/apple+notebooks'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"}\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Loop through each item and extract the required information\n",
    "    events = soup.findAll('div', {'class':'product-card__product-heading-title'})\n",
    "    for event in events:\n",
    "        print(event.text.strip())\n",
    "    \n",
    "    # Convert the list to a DataFrame\n",
    "   # df = pd.DataFrame(data)\n",
    "    \n",
    "   # df.to_csv('apple3.csv', index=False)\n",
    "#else:\n",
    "    #print(\"Failed to retrieve the webpage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to apple_notebooks.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = 'https://www.notebooksbilliger.de/notebooks/apple+notebooks'\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"}\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Initialize an empty list to store each item's information\n",
    "data = []\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Loop through each item and extract the required information\n",
    "    events = soup.findAll('div', {'class':'product-card__product-heading-title'})\n",
    "    \n",
    "    for event in events:\n",
    "        # For each item, create a dictionary with the extracted information\n",
    "        item_data = {\n",
    "            'item_title': event.text.strip()\n",
    "        }\n",
    "        # Append the dictionary to the data list\n",
    "        data.append(item_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Specify your desired CSV file name\n",
    "    csv_file_name = 'apple_notebooks.csv'\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_name, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {csv_file_name}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to apple_notebooks_with_prices_and_avaibility.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = 'https://www.notebooksbilliger.de/notebooks/apple+notebooks'\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"}\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Initialize an empty list to store each item's information\n",
    "data = []\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Assuming each product is encapsulated in a parent container for both title and price\n",
    "    products = soup.find_all('li', class_='product-listing__row', limit=10)\n",
    "    \n",
    "    for product in products:\n",
    "        # Extract the title\n",
    "        title_element = product.find('div', {'class':'product-card__product-heading-title'})\n",
    "        title = title_element.text.strip() if title_element else \"Title Not Found\"\n",
    "        \n",
    "        # Extract the price\n",
    "        price_element = product.find('div', {'class':'js-product-price product-price__price product-price__price--extra-large font--orange js-product-price'})\n",
    "        price = price_element.text.strip() if price_element else \"Price Not Found\"\n",
    "\n",
    "        #Extract the Availability\n",
    "        availability_element = product.find('div', {'class':'product-card__availability'})\n",
    "        availability = availability_element.text.strip() if availability_element else \"Availability Not Found\"\n",
    "\n",
    "        # Extract the evaluation (star rating)\n",
    "        rating_images = product.findAll('img', {'class': 'rating__star'})\n",
    "        evaluation = sum(1 for img in rating_images if 'full.svg' in img['src'])\n",
    "\n",
    "        # Extract the rating\n",
    "        ratingcount_element = product.find('div', {'class':'rating__row'})\n",
    "        ratingcount = ratingcount_element.text.strip() if ratingcount_element else \"Rating Not Found\"\n",
    "\n",
    "\n",
    "        # For each item, create a dictionary with the extracted information\n",
    "        item_data = {\n",
    "            'item_title': title,\n",
    "            'price': price,\n",
    "            'availability': availability,\n",
    "            'evaluation': evaluation,   \n",
    "            'rating': ratingcount\n",
    "        }\n",
    "        # Append the dictionary to the data list\n",
    "        data.append(item_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Specify your desired CSV file name\n",
    "    csv_file_name = 'apple_notebooks_with_prices_and_avaibility.csv'\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_name, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {csv_file_name}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"rating__row\">\n",
    "    <img src=\"/build/img/svg/general/product/rating-star-full.svg\" alt=\"1. Stern voll\" width=\"12\" height=\"12\" loading=\"lazy\" class=\"rating__star\">\n",
    "    <img src=\"/build/img/svg/general/product/rating-star-full.svg\" alt=\"2. Stern voll\" width=\"12\" height=\"12\" loading=\"lazy\" class=\"rating__star\">\n",
    "    <img src=\"/build/img/svg/general/product/rating-star-full.svg\" alt=\"3. Stern voll\" width=\"12\" height=\"12\" loading=\"lazy\" class=\"rating__star\">\n",
    "    <img src=\"/build/img/svg/general/product/rating-star-full.svg\" alt=\"4. Stern voll\" width=\"12\" height=\"12\" loading=\"lazy\" class=\"rating__star\">\n",
    "    <img src=\"/build/img/svg/general/product/rating-star-empty.svg\" alt=\"5. Stern leer\" width=\"12\" height=\"12\" loading=\"lazy\" class=\"rating__star\"> \n",
    "    <span class=\"rating__count\">(18)</span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
