{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc4922c-6e76-410e-9004-a9c68a9d6259",
   "metadata": {},
   "source": [
    "# Web Mining & Coginitive Computing - MSc 2025 - FS2024\n",
    "## Group Assignment 1\n",
    "\n",
    "Authors: **Bachem**, Kilian;\n",
    "**Mohr**, Otis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5317c2b3-e6ef-464f-be8e-4c8f6820301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all packages needed for the code below\n",
    "\n",
    "import requests # Needed for sending GET requests to the NBB website\n",
    "from bs4 import BeautifulSoup # Needed for finding and extracting elements from the request response\n",
    "import pandas as pd # Needed for generating/analyzing DataFrames\n",
    "from datetime import datetime # Needed for Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5e7b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dict variable 'links', which holds the NBB website URLs for each notebook brand\n",
    "links = {\n",
    "    \"acer\": \"https://www.notebooksbilliger.de/notebooks/acer+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"apple\": \"https://www.notebooksbilliger.de/notebooks/apple+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"asus\": \"https://www.notebooksbilliger.de/notebooks/asus+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"dell\": \"https://www.notebooksbilliger.de/notebooks/dell+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"hp\": \"https://www.notebooksbilliger.de/notebooks/hp+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"huawei\": \"https://www.notebooksbilliger.de/notebooks/huawei+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"lenovo\": \"https://www.notebooksbilliger.de/notebooks/lenovo+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"msi\": \"https://www.notebooksbilliger.de/notebooks/msi+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\",\n",
    "    \"samsung\": \"https://www.notebooksbilliger.de/notebooks/samsung+notebooks/page/1?perPage=50&sort=popularity&order=desc&availability=alle\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3429328-f3c8-4de6-9b36-98293f7dc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom request header that is used by the requests package to retrieve data from the NBB website. \n",
    "# The header suggests to the website that we are retrieving information from a regular browser.\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83aa35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed request for acer\n",
      "Completed request for apple\n",
      "Completed request for asus\n",
      "Completed request for dell\n",
      "Completed request for hp\n",
      "Completed request for huawei\n",
      "Completed request for lenovo\n",
      "Completed request for msi\n",
      "Completed request for samsung\n"
     ]
    }
   ],
   "source": [
    "### SCRAPING THE DATA FROM THE WEBSITE ###\n",
    "\n",
    "\n",
    "# Dictionary to store the request response for each brand webpage\n",
    "responses = {}\n",
    "\n",
    "\n",
    "# Next, iterate through all links, try retrieving the content and save them in the responses variable if the server responds with 200.\n",
    "for brand, url in links.items():\n",
    "    # Make a GET request to the URL\n",
    "    req = requests.get(url, headers=headers)\n",
    "\n",
    "    # ONLY if the server responds with 'OK' (in other words, the request was successful), go ahead and save the data.\n",
    "    if req.status_code == 200:\n",
    "        # Save the response under a variable name equal to the respective key value\n",
    "        responses[brand] = req\n",
    "        print(f\"Completed request for {brand}\")\n",
    "        time.sleep(8) # Delay of 8 seconds between queries for compliance\n",
    "    else:\n",
    "        # If the request fails, notify us that the request was unsuccessful\n",
    "        print(f\"Error {req.status_code} received when trying to retrieve data for {brand}\")\n",
    "        time.sleep(8) # Delay of 8 seconds between queries for compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "374b79a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA EXTRACTION ###\n",
    "\n",
    "# Create a new list in which the products for all brands will be stored later. Pre-fill the date at which the extraction was performed.\n",
    "# The actual data will be stored in a list in the 'data' key.\n",
    "all_data = {\n",
    "    'date-retrieved': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'data': []\n",
    "}\n",
    "    \n",
    "# Iterate through the server response for each brand page and filter out the relevant data of the first 10 products.\n",
    "for brand, data in responses.items():\n",
    "\n",
    "    # Create a BeautifulSoup object from the request html code\n",
    "    soup = BeautifulSoup(data.text, 'html')\n",
    "\n",
    "    # Assuming that every product is inside a HTML div  with the class 'product-card__content-wrapper'.\n",
    "    # Find 10 elements max which match the criteria, and save them in a new variable, 'products'.\n",
    "    products = soup.find_all('div', class_='product-card__content-wrapper', limit=10)\n",
    "\n",
    "    # Create a (temporary) list that will collect the product entries for one brand\n",
    "    brand_data = []\n",
    "\n",
    "    # Iterate through the products identified in the current soup object and extract only the desired data\n",
    "    for product in products:\n",
    "\n",
    "        # The vendor is already known, no need to extract it again.\n",
    "\n",
    "        # First, find the product title in the div with the class name 'product-card__product-heading-title\n",
    "        title_element = product.find('div', {'class':'product-card__product-heading-title'})\n",
    "        # Strip only the text and save it in the 'title' variable. If the title_element is empty, return a \"Not Found\" failsafe\n",
    "        title = title_element.text.strip() if title_element else \"Title Not Found\"\n",
    "\n",
    "        # Exact same method for the product price, also with a failsafe.\n",
    "        price_element = product.find('div', {'class':'js-product-price'})\n",
    "        price = price_element.text.strip() if price_element else \"Price Not Found\"\n",
    "\n",
    "        # Exact same method for the product availability, also with a failsafe.\n",
    "        availability_element = product.find('span', {'class':'product-detail__availability'})\n",
    "        availability = availability_element.text.strip() if availability_element else \"Availability Not Found\"\n",
    "\n",
    "        # Then, extract the evaluation (star rating). This is a bit more tricky, since we are only interested in the sum of filled stars.\n",
    "        # Thus, we count the number of star images in the rating which are ending in 'full.svg', therefore leaving out empty stars.\n",
    "        rating_images = product.findAll('img', {'class': 'rating__star'})\n",
    "        evaluation = sum(1 for img in rating_images if 'full.svg' in img['src'])\n",
    "\n",
    "        # Lastly, extract the rating count. Same method as in the beginning, with a failsafe.\n",
    "        # Also, getting rid of the parentheses and converting String into int\n",
    "        ratingcount_element = product.find('span', {'class':'rating__count'})\n",
    "        ratingcount = int(ratingcount_element.text.strip().replace('(','').replace(')','')) if ratingcount_element else \"Rating Not Found\"\n",
    "\n",
    "        \n",
    "        # Quick Console Output Tester. Uncomment to use. CONSIDER REMOVING THIS BEFORE HANDING IN THE ASSIGNMENT.\n",
    "        # print(f\"{title}: {price}. Availability: {availability}\\nRating: {evaluation} based on {ratingcount} ratings\\n\")\n",
    "\n",
    "\n",
    "        # For each item, create a (temporary) dictionary which aggregates the extracted information...\n",
    "        item_data = {\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'availability': availability,\n",
    "            'evaluation': evaluation,   \n",
    "            'ratingcount': ratingcount\n",
    "        }\n",
    "\n",
    "        #... and then add it to the list of items for the brand in the current iteration.\n",
    "        brand_data.append(item_data)\n",
    "\n",
    "    # After all items have been extracted for one brand, add the list of items to the all_data variable, in form of a dict.\n",
    "    brand_dict = {\n",
    "        'brand': brand,\n",
    "        'items': brand_data\n",
    "    }\n",
    "    all_data['data'].append(brand_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0333e36e-5240-4dd3-8b9a-81339d478e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to nbb_notebooks_allbrands.csv\n"
     ]
    }
   ],
   "source": [
    "### SAVING DATAFRAME AS CSV ###\n",
    "\n",
    "\n",
    "# Erstellung eines DataFrames aus der Gesamtliste\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Speichern des DataFrames in einer CSV-Datei\n",
    "csv_file_name = 'nbb_notebooks_allbrands.csv'\n",
    "df.to_csv(csv_file_name, index=False)\n",
    "print(f\"Data saved to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f427214f-e160-4ed5-9856-5b4bddf1fb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date-retrieved</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'acer', 'items': [{'title': 'Acer Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'apple', 'items': [{'title': 'Apple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'asus', 'items': [{'title': 'ASUS RO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'dell', 'items': [{'title': 'Dell La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'hp', 'items': [{'title': 'HP 250 G9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'huawei', 'items': [{'title': 'HUAWE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'lenovo', 'items': [{'title': 'Lenov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'msi', 'items': [{'title': 'MSI Thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-03-21 11:33:12</td>\n",
       "      <td>{'brand': 'samsung', 'items': [{'title': 'SAMS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date-retrieved                                               data\n",
       "0  2024-03-21 11:33:12  {'brand': 'acer', 'items': [{'title': 'Acer Ex...\n",
       "1  2024-03-21 11:33:12  {'brand': 'apple', 'items': [{'title': 'Apple ...\n",
       "2  2024-03-21 11:33:12  {'brand': 'asus', 'items': [{'title': 'ASUS RO...\n",
       "3  2024-03-21 11:33:12  {'brand': 'dell', 'items': [{'title': 'Dell La...\n",
       "4  2024-03-21 11:33:12  {'brand': 'hp', 'items': [{'title': 'HP 250 G9...\n",
       "5  2024-03-21 11:33:12  {'brand': 'huawei', 'items': [{'title': 'HUAWE...\n",
       "6  2024-03-21 11:33:12  {'brand': 'lenovo', 'items': [{'title': 'Lenov...\n",
       "7  2024-03-21 11:33:12  {'brand': 'msi', 'items': [{'title': 'MSI Thin...\n",
       "8  2024-03-21 11:33:12  {'brand': 'samsung', 'items': [{'title': 'SAMS..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
